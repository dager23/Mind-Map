{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "add15f6d",
   "metadata": {},
   "source": [
    "# Web Scraping and cleaning\n",
    "\n",
    "In this notebook we will be scraping the data from any given url and then use cleaning methods like regular expression to remove unwanted contents from the scraped text like unwanted spaces, \\n, \\t. Remove the citation marks like [6] or (ab) so we are left with only useful text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0cc755f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f664d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://en.wikipedia.org/wiki/Artificial_intelligence'\n",
    "html_page = requests.get(URL).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe030546",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs.BeautifulSoup(html_page, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "847af53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Artificial intelligence'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_heading = soup.find('h1').text\n",
    "main_heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59250ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Contents',\n",
       " 'History',\n",
       " 'Goals',\n",
       " 'Tools',\n",
       " 'Applications',\n",
       " 'Philosophy',\n",
       " 'Future',\n",
       " 'In fiction',\n",
       " 'Scientific diplomacy',\n",
       " 'See also',\n",
       " 'Explanatory notes',\n",
       " 'Citations',\n",
       " 'References']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heading_tags = soup.find_all('h2')\n",
    "headings = []\n",
    "for heading in heading_tags:\n",
    "    h = heading.text\n",
    "    h = h.replace(\"\\n\", \"\")\n",
    "    headings.append(h)\n",
    "headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38603592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reasoning, problem-solving',\n",
       " 'Knowledge representation',\n",
       " 'Planning',\n",
       " 'Learning',\n",
       " 'Natural language processing',\n",
       " 'Perception',\n",
       " 'Motion and manipulation',\n",
       " 'Social intelligence',\n",
       " 'General intelligence',\n",
       " 'Search and optimization',\n",
       " 'Logic',\n",
       " 'Probabilistic methods for uncertain reasoning',\n",
       " 'Classifiers and statistical learning methods',\n",
       " 'Artificial neural networks',\n",
       " 'Specialized languages and hardware',\n",
       " 'Defining artificial intelligence',\n",
       " 'Evaluating approaches to AI',\n",
       " 'Machine consciousness, sentience and mind',\n",
       " 'Superintelligence',\n",
       " 'Risks',\n",
       " 'Ethical machines',\n",
       " 'Regulation',\n",
       " 'Warfare',\n",
       " 'Cybersecurity',\n",
       " 'Election security',\n",
       " 'Future of work',\n",
       " 'AI and foreign policy',\n",
       " 'AI textbooks',\n",
       " 'History of AI',\n",
       " 'Other sources']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subheading_tags = soup.find_all('h3')\n",
    "subheadings = []\n",
    "for subheading in subheading_tags:\n",
    "    s = subheading.text\n",
    "    s = s.replace(\"\\n\", \"\")\n",
    "    subheadings.append(s)\n",
    "subheadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c63fb6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Many of these algorithms proved to be insufficient for solving large reasoning problems because they experienced a \"combinatorial explosion\": they became exponentially slower as the problems grew larger.Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments.\n"
     ]
    }
   ],
   "source": [
    "para_tags = soup.find_all('p')\n",
    "content = []\n",
    "citation_pattern = r\"([\\[]\\w*|[\\]])\"\n",
    "for para in para_tags:\n",
    "    p = para.text\n",
    "    p = p.replace(\"\\n\", \"\")\n",
    "    p = re.sub(citation_pattern, \"\", p)\n",
    "    if(p):\n",
    "        content.append(p)\n",
    "print(content[18])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839bce4d",
   "metadata": {},
   "source": [
    "## Making it into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f75cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(URL):\n",
    "    html_page = requests.get(URL).text\n",
    "    soup = bs.BeautifulSoup(html_page, 'lxml')\n",
    "    main_tags = soup.find_all('h1')\n",
    "    main_headings = []\n",
    "    spaces_pattern = r\"(  |\\r|\\n|\\t)\"\n",
    "    space_pattern = r'\\s+'\n",
    "    for main in main_tags:\n",
    "        m = main.text\n",
    "        m = re.sub(spaces_pattern, \"\", m)\n",
    "        main_headings.append(m)\n",
    "    \n",
    "    heading_tags = soup.find_all('h2')\n",
    "    headings = []\n",
    "    for heading in heading_tags:\n",
    "        h = heading.text\n",
    "        h = re.sub(spaces_pattern, \"\", h)\n",
    "        headings.append(h)\n",
    "    \n",
    "    subheading_tags = soup.find_all('h3')\n",
    "    subheadings = []\n",
    "    for subheading in subheading_tags:\n",
    "        s = subheading.text\n",
    "        s = re.sub(spaces_pattern, \"\", s)\n",
    "        subheadings.append(s)\n",
    "    \n",
    "    para_tags = soup.find_all('p')\n",
    "    content = []\n",
    "    citation_pattern = r\"([\\[]\\w*|[\\]])|([\\(]\\w*|[\\)])\"\n",
    "    citation_pattern = r'\\[[0-9a-zA-Z]*\\]'\n",
    "    for para in para_tags:\n",
    "        p = para.text\n",
    "        p = re.sub(spaces_pattern, \"\", p)\n",
    "        p = re.sub(citation_pattern, \"\", p)\n",
    "        if(p):\n",
    "            content.append(p)\n",
    "    \n",
    "    return (main_headings, headings, subheadings, content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db0e37c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_content('https://www.frontiersin.org/articles/10.3389/fpubh.2020.00014/full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4a40ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Air pollution has various health effects. The health of susceptible and sensitive individuals can be impacted even on low air pollution days. Short-term exposure to air pollutants is closely related to COPD (Chronic Obstructive Pulmonary Disease), cough, shortness of breath, wheezing, asthma, respiratory disease, and high rates of hospitalization (a measurement of morbidity).'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[3][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc98b654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    space_pattern = r\"(  |\\r|\\n|\\t)\"\n",
    "    citation_pattern = r'\\[[0-9a-zA-Z]*\\]'\n",
    "    text = re.sub(space_pattern, \" \", text)\n",
    "    text = re.sub(citation_pattern, \"\", text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e4fe572",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Direct Automatic Generation of Mind Maps from text with M2Gen  M. Abdeen, R. El-Sahan, A. Ismaeil, S. El-Harouny, M. Shalaby The Faculty of Computers and Information Sciences Ain-Shams University Cairo, Egypt mabdeen@alumni.uottawa.ca M. C.E. Yagoub  The school of Information Technology and Engineering University of Ottawa Ottawa, Ontario,  myagoub@site.uottawa.ca  Abstract—A  mind  map  is  a  diagram  used  to  represent  words, ideas,  or  other  items  linked  to  and  arranged  around  a  central keyword  or  idea.  Mind  maps  are  used  to  generate,  visualize, structure, and classify ideas, and as an aid in organization, study, project  management,    problem  solving,  decision  making,  and writing.  It  has  been  long  used  in  brainstorming  and  as  an effective educational tool. There are numerous tools in the  market, either  as freeware or as proprietary  software,  that  help  users  generate  mind  maps.. However,  these  tools  are  more  of  mind  map  “editing”  tools  to help  users  project  their  ideas  from  their  minds  into  the  tool mapping space. These tools also provide a comprehensive library of images that  suits  the most popular mind map  types.  The tools act  as  the  media  into  which  users  projects  the  maps  that  has already more-or-less matured in their minds. In  this  work,  we  present  a  software  tool  that  automatically generates  mind  maps  directly  from  text.  This  tool  provides  a prospect  to  transform  many  literatures automatically  into  mind maps. One  significant  application  of  this tool is education. Many students  finds  it  easier  to  follow  and  remember  information presented in the mid map form rather than pure text.  Keywords- text processing; semantic analysis; web mining. I. INTRODUCTION Mind mapping is a popular brainstorming tool and thinking technique  of  visually  arranging  ideas  and  their interconnections.  It  is  a  way  of  representing  associated thoughts with symbols rather than with extraneous words. The human  mind  forms  associations  almost  instantaneously,  and \"mapping\"  allows  capturing  these  ideas  quicker  than expressing them using only words or phrases. Originated  in  the  late  1960s  by  Tony  Buzan,   [1]  mind mapping  harnesses  the  full  range  of  cortical  skills  -  word, image, number, logic, rhythm, color and spatial awareness - in a single, uniquely powerful manner. In so doing, mind mapping gives the freedom to roam the infinite expanses of your brain. It is now used by millions of people around the world. A  mind  map  is  a diagram  used  to  represent  words, ideas, tasks, or  other  items linked  to  and  arranged  radially  around  a central  keyword.  As  an  example,   0  depicts  a  mind  map  of Google tools.  Figure 1   Google tools mind map  Manually  constructing  mind  maps  requires  thorough reading  and  good  understanding  the  text  which  takes  much time  and  effort.  In  addition  to  that  not  all  people  are  creative enough to  draw  elegant and expressive mind maps. Therefore, automatically  generating  mind  maps  saves  much  time  and effort and serves better and quicker various applications. Mind  mapping  applications  are  numerous.  Organizing, meetings, planning, note taking, presentation, and  above all, in education  [2]. There are  numerous tools in the market, either  as  freeware or as proprietary software, that help users generate mind maps. Wisemapping and Mindomo  [3] are  examples  of  the  freeware and Buzan’s iMindMap and Inspiration  [4] are examples of the proprietary ones. These softwares help the user in drawing the mind map and have some ready designs and diagrams which can be used. But the user must read, understand the text well and come up with a design for the mind map himself. Automatically  generating  mind  maps  out  of  pure  text requires  many  stages  of  text  processing.  In  the  following sections, we provide details of the main modules of the tool and the stages used to produce the final mind map.  TIC-STH 2009978-1-4244-3878-5/09/$25.00 ©2009 IEEE 95\\nII. ANALYSIS AND DESIGN The M2Gen tool consists of five modules: •••• Morphological Analyzer •••• Parser •••• Syntax Analyzer •••• Semantic Analyzer (which further consists of three sub-modules)  [9], [10]. •••• Mind map conversion  The role of each module is as follows: The  Morphological  Analyzer  is  concerned  by  how  words are  constructed  from  more  basic  units  called  morphemes.  It returns all possible morphemes for each word in the text. For  example:  Friendly  (Adjective)  =  friend  (noun)  +  ly (suffix)  The parser returns all possible parse  trees for each sentence in the  text  according  to  the  English  grammar  rules  in  effect.  A filtering process takes place in which the grammatically correct parse trees are chosen for each sentence. The Syntax Analyzer is  the  module  which  produces  the  final  correct  parse trees  of the input  text.  Further  filtering is done based  on  a  score  given to each parse tree based on its  internal structure. The  Semantic Analyzer receives correct parse trees of the text, selects correct meaning  for  each  word  and  produces  a  new  Text  Meaning Representation (TMR) or uses it to update an existing one. The Semantic  Analyzer  consists  of  three  sub-modules:  the Discourse Analyzer,  the  Word  Sense  Disambiguation  and  the Text  Meaning  Representation.  The  Discourse  Analyzer  is concerned with assigning each pronoun to the noun  which this pronoun  refers  to.  The  Word  Sense  Disambiguation  is concerned with assigning the most proper sense  for each word according to the formulation of the sentence. For example,  the word \"ball\" has several senses, including a round object used in games,  a  formal  dance,  and a  pitch  in  baseball  that  is  not  a strike.     Figure 2    Schematic representation of mind map generation modules   A  precise  method  for  quantifying  how  similar  two  word senses  are  is  called  a  measure  of  semantic  relatedness.  The Text Meaning Representation is concerned with putting the text in a  form  which best represents its meaning. Finally,  the mind map  conversion  module  obtains  candidate  pictures  by performing  a  Google  search  with  the  name  of  each  noun (including adjectives) and  each verb in  the  text  and  retrieving the  first  picture  found  [5],  thereby  drawing  the  mind  map. Figure 2 above depicts these modules and their interaction.  As an illustration for the design details of the tool modules, we  show  the  class  diagrams  for  the  mind  map  conversion module.  This  module  consists  of two  sub-modules,  the  mind map  viewing  management  module  and  the  drawing management module.  0  and  0  below show  the  class diagrams for these two modules.    Figure 3    The class diagram for the Mind Map conversion module    Figure 4    The class diagram for the drawing management module 96\\nIII. IMPLEMENTATION As mentioned previously, the tool consists of five modules. In this section we present the design, implementation notes and testing of the modules. For the morphological analysis module, we used the Microsoft WordNet 2.1 analyzer [6]. Generating a mind map requires the knowledge of the verb tense (for verbs) while for adjectives it is needed to know if it is comparative or superlative. The following modifications had  to be  introduced to the WordNet so that it can be used in mind map generation: 1. For regular  verbs  and  adjectives,  the  rules  return  the removed suffix to get the  morph  as additional output. The  verb  tense  is  determined  accordingly  (past  for “ed” and present for “s”). 2. For irregular  verbs  and adjectives the  reverse  of  their exceptional  lists  were  built.  That  list  will  later  be searched to determine a verb tense. In the remainder  of  this section we show in  details,  and as an  illustration,  the  design  of  the  syntactic  and  the  semantic analyzer modules. A. The Syntactic analyzer module This module consists  of  three classes. The Rules class,  the Parser class, and the Syntax class.  1) The Rules class It  is  a  simple  class  where  it  reads  the  rules  from  the “rules.txt” file  to  be applied  later  by  the parser  so  that  it  can build parse trees. 2) The Parser class This  class  contains  the  definition  of  two  data  structures namely the parse tree and parse node. It  is also responsible for constructing all the possible parse trees to the text. The Parser generates  all  correct parse trees for  every  input sentence according to  grammar rules. It consists of three parts: the  lexicon,  the  grammar,  and  the  parsing  algorithm.  For  the Lexicon, the WordNet 2.1 lexical database is used as a lexicon. It  includes  a  total  of  155327  words.  WordNet  2.1  lexical database  does  not  include  pronouns,  propositions  or conjunctions. Lists of pronouns, propositions and  conjunctions were added in separated files. For the Grammar rules, Context-free  grammar  rules  were  created  for  the  English  language  in “rules.txt”  file.  It  consists  of  651  CFG  rules.  Finally  for parsing,  a  Top-down  chart  parsing  algorithm  is implemented   [11].   0  depicts  a  class  diagram  for  the  parser class.  Figure 5    A detailed class diagram for the Parser class   3) The Syntax Analyzer class This  module  is  responsible  for  modification,  addition, deletion or selection of parse trees produced by the Parser. If a parse tree  doesn’t  follow  the  syntax  structure of its  verbs,  the parse tree is deleted. The  WordNet 2.1 verb syntax structure is used.  Each  parse  tree  is  given  a  certain  score  based  on  its structure.  Parse  trees  with  maximum score  are  selected.  The selection is based on grammatical and statistical basis. The  following  shows  an  example  to  test this  capability of the tool.  An  input text of “Shakespeare is a great writer in  the history  of  literature. He  was  born  in  1564.  …”.   0  shows  the output  that  corresponds  to  the  previous  text.  The  output  is divided  into  sentences  and  for  each,  syntax  analysis  is performed.    Figure 6    The output of the syntax analyzer module 97\\nB. The Semantic analyzer module Semantic  analysis  is  the  process  of  relating  syntactic structures,  from  the  levels  of  phrases,  clauses,  sentences  and paragraphs  to  the  level  of  the  writing  as  a  whole,  to  their language-independent meanings, removing features specific to particular linguistic and cultural contexts. It has three functions and each is performed by a separate module. 1) Word Sense Disambiguation (WSD):  This  module  is concerned  with assigning  the most  proper sense (meaning) for each word according to the structure of the sentence. 2) Discourse analysis This  module  is  basically  concerned  with  assigning  each pronoun to  the  noun  which  this  pronoun refers to.  It  includes the  implementation  of  the  RAP  algorithm   [12]  that  is concerned with assigning an antecedent noun to each pronoun. It depends on: • Selecting the nouns in the context. • Eliminating  the  nouns  which  do  not  agree  with  the pronoun in the person, number and gender. • Adding salience values to  each  noun  according  to  certain criteria. • Selecting  the  noun  with  the  maximum  salience  as  the anaphora (antecedent) of the pronoun. We have tested this module with the following text excerpt: “Shakespeare is  a great  writer  in  the  history  of  literature. He  was  born  in  1564  and  he had 3  children. He  was  earning his living from buying and selling the agricultural products. He lived in Stratford. He died in 1616” The output is as follows: SHAKESPEARE  (1.1),  HE  (2.1),  HE  (3.1),  HE  (4.1),  HIS (4.4), HE (5.1), HE (6.1)  The  first  word of  the output  is  the  antecedent  noun  that  the pronouns  refer  to  .In  our  example,  Shakespeare  and  (1.1) means  that  Shakespeare  is  the  word  number  1  in  sentence number  1  (sentence number  “dot”  word  number). “He  (2.1)” means that  \"He\"  is  the  word  number 1 in sentence  number  2, which  also  refers  to  Shakespeare  in  the  first  sentence.  The same thing goes for \"He (3.1)\" and so on.  Figure 7 below  shows the  output  of  the  “Discourse Analysis” module of the tool.   Figure 7     The output of the discourse analysis module of the tool    3) Meaning Representation class The verbs, adverbs, nouns and  adjectives  in each sentence are extracted along with any relations (case roles) between words. This  sub-module  is  totally  dependent  on  the correctly  chosen parse  trees  from  the  Syntax  Analyzer.  A  Case  Role  is  an argument or typical role that a predicate can take. It appears as a property  of an  event  (verb)  in  a  TMR.  For  example,  in  the sentence \"Shakespeare was born in 1564,\" \"born\" is the  event (verb),  the  verb  is  passive  therefore  \"Shakespeare\"  is  the theme  case  role  (the  party  that  was  affected  by  the  verb), \"1564\"  is the  time  case  role of  the  event.  There  are  several other  case  roles  including:  Agent  (The  party performing  the action), Source, Destination, Location, etc.  The  following  Figure  is the Text  Meaning  Representation  for the Shakespeare excerpt that was used above.           Figure 8     Text Meaning Representation  IV. RESULTS To demonstrate the tool’s capabilities we have run a simple test on a text defining Shakespeare, the great writer. The text is the one listed in the previous section. 98\\nThe following Figure is the final mind map.   Figure 9     Final mind map of the Shakespeare text  It  is  to  be  noted that  some  of  the images  assigned  to the nodes are not accurately representing them. This is essentially due to the way Google image search is tuned to perform image retrieval.  There  are  two  approaches  to  solving  this  problem. The  first  is  to  choose  tighter  search  criteria  for  Google  that eliminates any ambiguity in the search. The second is to create a  complete  image  database.  The  latter  option  is  what  we adopted  in  the  improvements  we  are  currently  performing  on this tool. V. CONCLUSIONS AND FUTURE WORK In  this  paper,  we  presented  M2Gen,  a  software  tool  that automatically generates mind maps from input text. To the best of  our  knowledge,  this  is  the  first  time  this  tool  is presented. Due to the size of the English language and the variety of rules within  it,  the  current  version  of  the  tool  covers  a  relatively small subset  of  the  English  language.  More  work  is  currently being done to  expand  the  scope  of  the  tool  to  include  a  larger subset of the language. On  the  other  hand,  the  current  version only  supports  single  layer  mind map  and does  not  produce a hierarchical (multileveled)  map  (i.e.,  maps  within  maps). This is  because  not  all  the  information  extracted  from  the  text  is displayed in one mind map, but only the most important nouns and verbs are. This means  that if  further  information needs to be obtained  about a certain node,  if there is more  information, it is presented as a separate mind map with that certain node as the  central  node  or  main topic. We  also  have  current work in this area. In addition to that, we are working on improving the image production module to be able to synthesize images form a very small and manageable database other than using Google image search facility. This has  the  advantage  of  allowing the  tool  to work  offline  and  to  eliminate  any  network  delays  during  the search process. \\n\\nA mind map is a diagram used to represent words, ideas, tasks, or other items linked to and arranged around a central key word or idea. Mind maps are used to generate, visualize, structure, and classify ideas, and as an aid to studying and organizing information, solving problems, making decisions, and writing. We can see that there are numerous applications of mind maps in many areas. There are also many research articles about mind maps and their applications. One of the main purposes of mind maps is to aid in education, to organize knowledge in a structured way.  A mind map can be used as a teaching resource [9]. It can be used in education of specific group of students [7]. Research has shown that cognitive structures of knowledge are better in learning with mind maps then traditional way [8]. There has been also research on teachers and the results showed that mind maps are good aid in oral lessons [15]. We can say that mind maps are very useful in the field of education. It’s much easier to understand well structured data instead of unstructured. Mind maps can be used as a tool to model semi structured documents [4], to organize data in a more intuitive way. There are many areas where mind maps can help us. Today, it’s not a problem to get information, since the Internet is a huge information resource. But to get high quality information, we need good search engines. Using mind maps, we can make expert search, document summarization [3] and speed up search process and get more relevant information [2]. Using mind maps can help us filter search results in a better way, better than traditional page ranking system [20]. There is also research in the area of cognitive functions. There is a research where use of cognitive mind maps can help us in fostering trust [13]. Also there is a research where mind maps are used in creating conceptual design, to fully develop designers’ potential [11], to help in keeping the balance of science and arts, as well as logical and imaginary thinking. Mind maps can be used to better understand and analyze conversation streams [14]. So there are many possibilities of application of mind maps in this field. Mind maps can be used in the process of organizing and planning. Some researchers recommend using mind maps in analysis and e-government design [18]. With the use of mind maps it’s easier to get a broad overall view, focus on the details, get a better understanding of implementation, etc. Another article shows how the use of mind maps can help us in health service to make qualitative data analysis where time is crucial [5]. There are also some very interesting articles on use of mind maps, like algorithm that can help us generate ideas using mind maps [12]. There is also a suggestion for a new model of mind maps called mind maps of the next generation [17]. This model would bring mind maps with association, back-tracking, comparison and 487Proceedings of the ITI 2011 33rd Int. Conf. on Information Technology Interfaces, June 27-30, 2011, Cavtat, Croatia \\ncognitive functionality together with new way of connecting elements of mind maps. There are many mind map tools that can help us make a mind map, such as Compendium, FreeMind, Freeplane, SciPlore MindMapping, Cacoo, Inspiration, MindGenius, MindMapper, Mindomo, NovaMind, Semantica, Visual Mind etc. But there are no tools that can generate mind maps from text. In order to create a mind map, we have to know how to make one, read the text, create the mind map and all the help we have are editing tools for drawing mind maps. These tools don’t differentiate from some other diagram editing tools. The idea to automatically generate mind maps from row documents is not new [1]. However, the integration of automatic mind map generation feature with standard manual mind map creation software possibilities is rather new and it opens wide research possibilities in the field of artificial intelligence, text mining, machine learning et cetera. Also, let’s not forget use of mind maps in knowledge management where it is critical to rapidly discover, interpret, share and reason over the data [19] [16]. In this article, we will describe our idea of the mind map generator software. We will point out the key features and functionality that this kind of software should have. We will also point out the main problems we have to deal with and propose adequate solutions for them. Also, we will describe problems that occur in our case when we are text mining through our custom developed algorithm and give a few examples of its runtime execution.   2. Model description  2.1. Problem description  As we’ve seen in the introduction, there are many areas where we can use mind maps, but let’s look at the problems that are present today.  Firstly, there is so much data/information to process that it’s nearly impossible to do it. Internet is a database with an enormous amount of information. Secondly, we have a limited amount of time to do it. Therefore we have to find a way to process information in a more efficient way. We need to structure data in a timely fashionable manner.  Sometimes it’s hard to understand and comprehend the problem we’re dealing with. Another problem is that it’s hard to remember all the data we need in the future. Fig. 1 shows what the percentage of data we remember after an hour, two or three hours, based on the [10]. How do we transfer knowledge from short-term memory to long-term memory? We will describe a model of a mind map generator software. This system can help us get relevant information from unstructured and semi-structured data much quicker. It can also help in the learning process; make it easier and more intuitive. With generated mind maps you need to process less information in a shorter time frame. With mind map database we can integrate knowledge in various fields. It will help in searching big documents quickly and efficiently. This system will be able to represent data, information or knowledge in a new way that is easier to comprehend.    Figure 1. How much do we remember  2.2. Visual appearance    Figure 2. Example of mind map Tony Buzan, the author of the book on mind maps recommends what features mind maps should have [6]. We will mention those related to our work: 488\\n• Use words, pictures, colors and dimensions throughout your mind map • Lines should connect a whole mind map, central lines are thicker and they get thinner as they radiate from the centre. • Each word should have its own picture • Develop your own style of mind mapping • Keep the mind map clear by using radial hierarchy  Based on these features we can determine how our generated mind map should look like. The map will be generated from its central word. Based on the number of terms that are directly connected to this central word, we will evenly make radial links to those terms. All the other levels of the mind map won’t follow the same rule. Every new level that connects to core terms of a mind map must develop in the direction away from the central point so we don’t get the case where word that’s on the 2nd level is closer to the central word than the word on the 1st level.  The lines will be in different colors so that each category on the 1st level will have its own color.  Each word will also have its own unique picture; hence the picture in the center will be the largest, while other pictures will become smaller as they move away from the center. The same rule applies to words and lines, so the ones on the lower levels will be smaller and thinner. With this combination of words, pictures, colors, their sizes and thicknesses, we create much stronger cognitive structures of knowledge [6].  2.3. System architecture and functionality  This software should work on home computers, laptops, PDAs and even cell phones. Home computers and laptops are powerful enough to execute mind map generation algorithms, however the execution on PDAs and mobile phones would be somewhat slow. Therefore we recommend the system to be based on SOA, using web service. PDAs and mobile phones can send input data, web page link, to a web service. The web service will then execute the algorithms and generate a mind map and send the generated mind map back to users. There is another reason why we are going to use web service and database server. We will store all generated mind maps on our database server so each user can search and download all the mind maps created. When somebody generates a mind map, if there are mind maps around the same word in our database, we can recommend him those mind maps. After a period of time, we will have a big database with lots of mind maps and we can then use it for mind map integration and further research. Fig. 3 shows how we’re planning to implement this system.     Figure 3. System architecture  Considering that pictures are a very important part of mind maps, we will use our server architecture to create a big database of pictures that are suitable for each word. We will make initial database with pictures for most common words, so the system will automatically place the pictures in the generated mind maps. For words without a picture in our database, users will be able to upload their own pictures. After a period of time, we will again have multiple suitable pictures for each of the words; therefore the users will be able to choose pictures they like for each word in their mind maps. They will always have an option of changing pictures of the given keywords because every person has different associations and it is very likely that not all automatically selected pictures will give appropriate associations for every user. More importantly, every user will probably always change at least a few pictures to adapt the generated mind map associations to his/her liking. Earlier in the text we’ve mentioned it was good for users to develop their own styles of mind mapping. Therefore we will provide editing features which will make it possible for the users to edit their mind maps. They will be able to 489\\nrearrange nodes, change colors, pictures and words. They will be able to fully customize their mind maps.  The most important part of this software will be the algorithms that actually generate mind maps. Those algorithms should, among other things, analyze given text through relations between words in sentences, relations between sentences and between paragraphs, parsing of words that are irrelevant and based on those results, etc. After this analysis we can automatically generate mind map for a given text. If we look at this problem, we can’t just look headers of documents or some meta-data. This kind of algorithmic analysis would be a good starting point but for entirely plain texts it would not work. The algorithms should give good results for any given text, and we can’t predict in which form the text will be. The details about these algorithms will be presented in upcoming papers since this is the paper that describes the basic model of this system and algorithms for text-mining. When a mind map is generated, the user will be able to browse it, he will be able to search any term that was in the original text, and the search results will automatically mark nodes that are related with the search term. Also, when a user clicks on a particular node, he will see only the text relevant to that particular node. These are the main features that we consider important for a mind map generator to have.  If we want to generate a mind map from a text the first thing we need is an algorithm that will parse this text. In the following section we will give a few examples of this parser at work.  3. Text-mining algorithm  For every text that we want to generate a mind map from we need an algorithm that will parse the text and extract useful structured data. We need a text source as an input (document, web page) and this algorithm will give us extracted text for mind map generation as an output. The extracted text will be an input for the algorithm that will actually generate a mind map. If we have a pdf, doc, rtf or a document of another similar extension, there are no problems in text extraction since all we need to do is just take the entire content of the document. But, if we have a web page as a text source then we have a problem, since, obviously the needed text has to be extracted from the web code and here we need somewhat smarter algorithm that will do this extraction. If a web page is coded according to W3C standards the only thing that has to be done is to write a small algorithm with just a few regular expressions since it is not so difficult to find patterns in the code. There are also pages that do not conform to these laid out standards, and in order to resolve this situation we need a more complex special algorithm which will try the best it can to extract the text. The reason why it’s difficult to extract this text from a web page that does not conform to W3C standard is that these pages are poorly structured; the tags are badly encapsulated, unclosed, etc. Let’s first take a look at the pseudo code for this algorithm that we have developed and after that we will give some examples of inputs and outputs of the mentioned algorithm at runtime. Pseudo code: Input:  Text from the following data sources (doc, docx, pdf, txt, rtf, web-page) Output:  extracted text IF (data source = doc || docx || pdf || txt || rtf) Extract text data from the source document through standard algorithms for document manipulation ELSE Determine if web page conforms to W3C standards IF (conforms) Execute regular expressions to extract data from data source according to standard web-page structure laid out by the W3C ELSE Determine position of the text in the code through global code structure Refine text positioning through selective tag encapsulation Extract text from the code  Now that we know how this algorithm works let’s see few examples of its execution. Extraction from documents will not be covered since this task is trivial but we will, of course, cover text extraction from web pages. Let’s see a few examples of text extraction from web pages that do not conform to W3C standards.   Data source:   http://edition.cnn.com/2011/OPINION/02/10/opinion.roundup.egypt/index.html?hpt=C2 loaded: 11. 02. 2011. W3C markup validation: 67 errors and 22 warnings. Results: Everything relevant was extracted from the web page, therefore, this web data source was 490\\nextracted satisfactory. Nevertheless, algorithm did make one mistake because it extracted a sentence that is not a part of the main text. Overall, these are good results since this mistake is a minor problem and probably won’t influence the mind map generator that will be developed.  Data source: http://en.wikipedia.org/wiki/Mind_map loaded: 11. 02. 2011. W3C markup validation: 2 errors. 4. Conclusion and further research  Mind maps are very useful in different fields, like learning, memorizing, structuring data and speeding up the search process; we could process much more information in less time etc. The process of creating a mind map is slow, and all the tools today are just editors that help us create mind maps. So if we generate mind maps from plain text, that reduces much of the time required to make mind maps and then we could focus on using them. We plan to develop a system that is based on this model, with all the features that we described. Further research is needed to implement all the features of this model. The developed text-mining algorithm will be a part of this system and outputs of this algorithm will be passed to a mind-map generator algorithm that is still in development.  Development of such a system would contribute to the popularization of mind maps and we believe it would greatly increase the use of mind maps in many areas. Also, this compact way of presenting data with mind maps and then creating information and new knowledge from them is very useful in knowledge management where we could even implement some kind of reasoning over these maps and information that we created.   '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./SampleData/sample_text4.txt', encoding=\"utf8\") as f:\n",
    "    input_text = f.readlines()\n",
    "final_text = ''\n",
    "for text in input_text:\n",
    "    final_text += text\n",
    "    \n",
    "final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd86a8cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Direct Automatic Generation of Mind Maps from text with M2Gen M. Abdeen, R. El-Sahan, A. Ismaeil, S. El-Harouny, M. Shalaby The Faculty of Computers and Information Sciences Ain-Shams University Cairo, Egypt mabdeen@alumni.uottawa.ca M. C.E. Yagoub The school of Information Technology and Engineering University of Ottawa Ottawa, Ontario, myagoub@site.uottawa.ca Abstract—A mind map is a diagram used to represent words, ideas, or other items linked to and arranged around a central keyword or idea. Mind maps are used to generate, visualize, structure, and classify ideas, and as an aid in organization, study, project management,  problem solving, decision making, and writing. It has been long used in brainstorming and as an effective educational tool. There are numerous tools in the market, either as freeware or as proprietary software, that help users generate mind maps.. However, these tools are more of mind map “editing” tools to help users project their ideas from their minds into the tool mapping space. These tools also provide a comprehensive library of images that suits the most popular mind map types. The tools act as the media into which users projects the maps that has already more-or-less matured in their minds. In this work, we present a software tool that automatically generates mind maps directly from text. This tool provides a prospect to transform many literatures automatically into mind maps. One significant application of this tool is education. Many students finds it easier to follow and remember information presented in the mid map form rather than pure text. Keywords- text processing; semantic analysis; web mining. I. INTRODUCTION Mind mapping is a popular brainstorming tool and thinking technique of visually arranging ideas and their interconnections. It is a way of representing associated thoughts with symbols rather than with extraneous words. The human mind forms associations almost instantaneously, and \"mapping\" allows capturing these ideas quicker than expressing them using only words or phrases. Originated in the late 1960s by Tony Buzan,   mind mapping harnesses the full range of cortical skills - word, image, number, logic, rhythm, color and spatial awareness - in a single, uniquely powerful manner. In so doing, mind mapping gives the freedom to roam the infinite expanses of your brain. It is now used by millions of people around the world. A mind map is a diagram used to represent words, ideas, tasks, or other items linked to and arranged radially around a central keyword. As an example,  0 depicts a mind map of Google tools. Figure 1  Google tools mind map Manually constructing mind maps requires thorough reading and good understanding the text which takes much time and effort. In addition to that not all people are creative enough to draw elegant and expressive mind maps. Therefore, automatically generating mind maps saves much time and effort and serves better and quicker various applications. Mind mapping applications are numerous. Organizing, meetings, planning, note taking, presentation, and above all, in education . There are numerous tools in the market, either as freeware or as proprietary software, that help users generate mind maps. Wisemapping and Mindomo  are examples of the freeware and Buzan’s iMindMap and Inspiration  are examples of the proprietary ones. These softwares help the user in drawing the mind map and have some ready designs and diagrams which can be used. But the user must read, understand the text well and come up with a design for the mind map himself. Automatically generating mind maps out of pure text requires many stages of text processing. In the following sections, we provide details of the main modules of the tool and the stages used to produce the final mind map. TIC-STH 2009978-1-4244-3878-5/09/$25.00 ©2009 IEEE 95 II. ANALYSIS AND DESIGN The M2Gen tool consists of five modules: •••• Morphological Analyzer •••• Parser •••• Syntax Analyzer •••• Semantic Analyzer (which further consists of three sub-modules) , . •••• Mind map conversion The role of each module is as follows: The Morphological Analyzer is concerned by how words are constructed from more basic units called morphemes. It returns all possible morphemes for each word in the text. For example: Friendly (Adjective) = friend (noun) + ly (suffix) The parser returns all possible parse trees for each sentence in the text according to the English grammar rules in effect. A filtering process takes place in which the grammatically correct parse trees are chosen for each sentence. The Syntax Analyzer is the module which produces the final correct parse trees of the input text. Further filtering is done based on a score given to each parse tree based on its internal structure. The Semantic Analyzer receives correct parse trees of the text, selects correct meaning for each word and produces a new Text Meaning Representation (TMR) or uses it to update an existing one. The Semantic Analyzer consists of three sub-modules: the Discourse Analyzer, the Word Sense Disambiguation and the Text Meaning Representation. The Discourse Analyzer is concerned with assigning each pronoun to the noun which this pronoun refers to. The Word Sense Disambiguation is concerned with assigning the most proper sense for each word according to the formulation of the sentence. For example, the word \"ball\" has several senses, including a round object used in games, a formal dance, and a pitch in baseball that is not a strike.   Figure 2  Schematic representation of mind map generation modules  A precise method for quantifying how similar two word senses are is called a measure of semantic relatedness. The Text Meaning Representation is concerned with putting the text in a form which best represents its meaning. Finally, the mind map conversion module obtains candidate pictures by performing a Google search with the name of each noun (including adjectives) and each verb in the text and retrieving the first picture found , thereby drawing the mind map. Figure 2 above depicts these modules and their interaction. As an illustration for the design details of the tool modules, we show the class diagrams for the mind map conversion module. This module consists of two sub-modules, the mind map viewing management module and the drawing management module. 0 and 0 below show the class diagrams for these two modules.  Figure 3  The class diagram for the Mind Map conversion module  Figure 4  The class diagram for the drawing management module 96 III. IMPLEMENTATION As mentioned previously, the tool consists of five modules. In this section we present the design, implementation notes and testing of the modules. For the morphological analysis module, we used the Microsoft WordNet 2.1 analyzer . Generating a mind map requires the knowledge of the verb tense (for verbs) while for adjectives it is needed to know if it is comparative or superlative. The following modifications had to be introduced to the WordNet so that it can be used in mind map generation: 1. For regular verbs and adjectives, the rules return the removed suffix to get the morph as additional output. The verb tense is determined accordingly (past for “ed” and present for “s”). 2. For irregular verbs and adjectives the reverse of their exceptional lists were built. That list will later be searched to determine a verb tense. In the remainder of this section we show in details, and as an illustration, the design of the syntactic and the semantic analyzer modules. A. The Syntactic analyzer module This module consists of three classes. The Rules class, the Parser class, and the Syntax class. 1) The Rules class It is a simple class where it reads the rules from the “rules.txt” file to be applied later by the parser so that it can build parse trees. 2) The Parser class This class contains the definition of two data structures namely the parse tree and parse node. It is also responsible for constructing all the possible parse trees to the text. The Parser generates all correct parse trees for every input sentence according to grammar rules. It consists of three parts: the lexicon, the grammar, and the parsing algorithm. For the Lexicon, the WordNet 2.1 lexical database is used as a lexicon. It includes a total of 155327 words. WordNet 2.1 lexical database does not include pronouns, propositions or conjunctions. Lists of pronouns, propositions and conjunctions were added in separated files. For the Grammar rules, Context-free grammar rules were created for the English language in “rules.txt” file. It consists of 651 CFG rules. Finally for parsing, a Top-down chart parsing algorithm is implemented  .  0 depicts a class diagram for the parser class. Figure 5  A detailed class diagram for the Parser class  3) The Syntax Analyzer class This module is responsible for modification, addition, deletion or selection of parse trees produced by the Parser. If a parse tree doesn’t follow the syntax structure of its verbs, the parse tree is deleted. The WordNet 2.1 verb syntax structure is used. Each parse tree is given a certain score based on its structure. Parse trees with maximum score are selected. The selection is based on grammatical and statistical basis. The following shows an example to test this capability of the tool. An input text of “Shakespeare is a great writer in the history of literature. He was born in 1564. …”.  0 shows the output that corresponds to the previous text. The output is divided into sentences and for each, syntax analysis is performed.  Figure 6  The output of the syntax analyzer module 97 B. The Semantic analyzer module Semantic analysis is the process of relating syntactic structures, from the levels of phrases, clauses, sentences and paragraphs to the level of the writing as a whole, to their language-independent meanings, removing features specific to particular linguistic and cultural contexts. It has three functions and each is performed by a separate module. 1) Word Sense Disambiguation (WSD): This module is concerned with assigning the most proper sense (meaning) for each word according to the structure of the sentence. 2) Discourse analysis This module is basically concerned with assigning each pronoun to the noun which this pronoun refers to. It includes the implementation of the RAP algorithm   that is concerned with assigning an antecedent noun to each pronoun. It depends on: • Selecting the nouns in the context. • Eliminating the nouns which do not agree with the pronoun in the person, number and gender. • Adding salience values to each noun according to certain criteria. • Selecting the noun with the maximum salience as the anaphora (antecedent) of the pronoun. We have tested this module with the following text excerpt: “Shakespeare is a great writer in the history of literature. He was born in 1564 and he had 3 children. He was earning his living from buying and selling the agricultural products. He lived in Stratford. He died in 1616” The output is as follows: SHAKESPEARE (1.1), HE (2.1), HE (3.1), HE (4.1), HIS (4.4), HE (5.1), HE (6.1) The first word of the output is the antecedent noun that the pronouns refer to .In our example, Shakespeare and (1.1) means that Shakespeare is the word number 1 in sentence number 1 (sentence number “dot” word number). “He (2.1)” means that \"He\" is the word number 1 in sentence number 2, which also refers to Shakespeare in the first sentence. The same thing goes for \"He (3.1)\" and so on. Figure 7 below shows the output of the “Discourse Analysis” module of the tool.  Figure 7   The output of the discourse analysis module of the tool  3) Meaning Representation class The verbs, adverbs, nouns and adjectives in each sentence are extracted along with any relations (case roles) between words. This sub-module is totally dependent on the correctly chosen parse trees from the Syntax Analyzer. A Case Role is an argument or typical role that a predicate can take. It appears as a property of an event (verb) in a TMR. For example, in the sentence \"Shakespeare was born in 1564,\" \"born\" is the event (verb), the verb is passive therefore \"Shakespeare\" is the theme case role (the party that was affected by the verb), \"1564\" is the time case role of the event. There are several other case roles including: Agent (The party performing the action), Source, Destination, Location, etc. The following Figure is the Text Meaning Representation for the Shakespeare excerpt that was used above.      Figure 8   Text Meaning Representation IV. RESULTS To demonstrate the tool’s capabilities we have run a simple test on a text defining Shakespeare, the great writer. The text is the one listed in the previous section. 98 The following Figure is the final mind map.  Figure 9   Final mind map of the Shakespeare text It is to be noted that some of the images assigned to the nodes are not accurately representing them. This is essentially due to the way Google image search is tuned to perform image retrieval. There are two approaches to solving this problem. The first is to choose tighter search criteria for Google that eliminates any ambiguity in the search. The second is to create a complete image database. The latter option is what we adopted in the improvements we are currently performing on this tool. V. CONCLUSIONS AND FUTURE WORK In this paper, we presented M2Gen, a software tool that automatically generates mind maps from input text. To the best of our knowledge, this is the first time this tool is presented. Due to the size of the English language and the variety of rules within it, the current version of the tool covers a relatively small subset of the English language. More work is currently being done to expand the scope of the tool to include a larger subset of the language. On the other hand, the current version only supports single layer mind map and does not produce a hierarchical (multileveled) map (i.e., maps within maps). This is because not all the information extracted from the text is displayed in one mind map, but only the most important nouns and verbs are. This means that if further information needs to be obtained about a certain node, if there is more information, it is presented as a separate mind map with that certain node as the central node or main topic. We also have current work in this area. In addition to that, we are working on improving the image production module to be able to synthesize images form a very small and manageable database other than using Google image search facility. This has the advantage of allowing the tool to work offline and to eliminate any network delays during the search process.   A mind map is a diagram used to represent words, ideas, tasks, or other items linked to and arranged around a central key word or idea. Mind maps are used to generate, visualize, structure, and classify ideas, and as an aid to studying and organizing information, solving problems, making decisions, and writing. We can see that there are numerous applications of mind maps in many areas. There are also many research articles about mind maps and their applications. One of the main purposes of mind maps is to aid in education, to organize knowledge in a structured way. A mind map can be used as a teaching resource . It can be used in education of specific group of students . Research has shown that cognitive structures of knowledge are better in learning with mind maps then traditional way . There has been also research on teachers and the results showed that mind maps are good aid in oral lessons . We can say that mind maps are very useful in the field of education. It’s much easier to understand well structured data instead of unstructured. Mind maps can be used as a tool to model semi structured documents , to organize data in a more intuitive way. There are many areas where mind maps can help us. Today, it’s not a problem to get information, since the Internet is a huge information resource. But to get high quality information, we need good search engines. Using mind maps, we can make expert search, document summarization  and speed up search process and get more relevant information . Using mind maps can help us filter search results in a better way, better than traditional page ranking system . There is also research in the area of cognitive functions. There is a research where use of cognitive mind maps can help us in fostering trust . Also there is a research where mind maps are used in creating conceptual design, to fully develop designers’ potential , to help in keeping the balance of science and arts, as well as logical and imaginary thinking. Mind maps can be used to better understand and analyze conversation streams . So there are many possibilities of application of mind maps in this field. Mind maps can be used in the process of organizing and planning. Some researchers recommend using mind maps in analysis and e-government design . With the use of mind maps it’s easier to get a broad overall view, focus on the details, get a better understanding of implementation, etc. Another article shows how the use of mind maps can help us in health service to make qualitative data analysis where time is crucial . There are also some very interesting articles on use of mind maps, like algorithm that can help us generate ideas using mind maps . There is also a suggestion for a new model of mind maps called mind maps of the next generation . This model would bring mind maps with association, back-tracking, comparison and 487Proceedings of the ITI 2011 33rd Int. Conf. on Information Technology Interfaces, June 27-30, 2011, Cavtat, Croatia  cognitive functionality together with new way of connecting elements of mind maps. There are many mind map tools that can help us make a mind map, such as Compendium, FreeMind, Freeplane, SciPlore MindMapping, Cacoo, Inspiration, MindGenius, MindMapper, Mindomo, NovaMind, Semantica, Visual Mind etc. But there are no tools that can generate mind maps from text. In order to create a mind map, we have to know how to make one, read the text, create the mind map and all the help we have are editing tools for drawing mind maps. These tools don’t differentiate from some other diagram editing tools. The idea to automatically generate mind maps from row documents is not new . However, the integration of automatic mind map generation feature with standard manual mind map creation software possibilities is rather new and it opens wide research possibilities in the field of artificial intelligence, text mining, machine learning et cetera. Also, let’s not forget use of mind maps in knowledge management where it is critical to rapidly discover, interpret, share and reason over the data  . In this article, we will describe our idea of the mind map generator software. We will point out the key features and functionality that this kind of software should have. We will also point out the main problems we have to deal with and propose adequate solutions for them. Also, we will describe problems that occur in our case when we are text mining through our custom developed algorithm and give a few examples of its runtime execution.  2. Model description 2.1. Problem description As we’ve seen in the introduction, there are many areas where we can use mind maps, but let’s look at the problems that are present today. Firstly, there is so much data/information to process that it’s nearly impossible to do it. Internet is a database with an enormous amount of information. Secondly, we have a limited amount of time to do it. Therefore we have to find a way to process information in a more efficient way. We need to structure data in a timely fashionable manner. Sometimes it’s hard to understand and comprehend the problem we’re dealing with. Another problem is that it’s hard to remember all the data we need in the future. Fig. 1 shows what the percentage of data we remember after an hour, two or three hours, based on the . How do we transfer knowledge from short-term memory to long-term memory? We will describe a model of a mind map generator software. This system can help us get relevant information from unstructured and semi-structured data much quicker. It can also help in the learning process; make it easier and more intuitive. With generated mind maps you need to process less information in a shorter time frame. With mind map database we can integrate knowledge in various fields. It will help in searching big documents quickly and efficiently. This system will be able to represent data, information or knowledge in a new way that is easier to comprehend.  Figure 1. How much do we remember 2.2. Visual appearance  Figure 2. Example of mind map Tony Buzan, the author of the book on mind maps recommends what features mind maps should have . We will mention those related to our work: 488 • Use words, pictures, colors and dimensions throughout your mind map • Lines should connect a whole mind map, central lines are thicker and they get thinner as they radiate from the centre. • Each word should have its own picture • Develop your own style of mind mapping • Keep the mind map clear by using radial hierarchy Based on these features we can determine how our generated mind map should look like. The map will be generated from its central word. Based on the number of terms that are directly connected to this central word, we will evenly make radial links to those terms. All the other levels of the mind map won’t follow the same rule. Every new level that connects to core terms of a mind map must develop in the direction away from the central point so we don’t get the case where word that’s on the 2nd level is closer to the central word than the word on the 1st level. The lines will be in different colors so that each category on the 1st level will have its own color. Each word will also have its own unique picture; hence the picture in the center will be the largest, while other pictures will become smaller as they move away from the center. The same rule applies to words and lines, so the ones on the lower levels will be smaller and thinner. With this combination of words, pictures, colors, their sizes and thicknesses, we create much stronger cognitive structures of knowledge . 2.3. System architecture and functionality This software should work on home computers, laptops, PDAs and even cell phones. Home computers and laptops are powerful enough to execute mind map generation algorithms, however the execution on PDAs and mobile phones would be somewhat slow. Therefore we recommend the system to be based on SOA, using web service. PDAs and mobile phones can send input data, web page link, to a web service. The web service will then execute the algorithms and generate a mind map and send the generated mind map back to users. There is another reason why we are going to use web service and database server. We will store all generated mind maps on our database server so each user can search and download all the mind maps created. When somebody generates a mind map, if there are mind maps around the same word in our database, we can recommend him those mind maps. After a period of time, we will have a big database with lots of mind maps and we can then use it for mind map integration and further research. Fig. 3 shows how we’re planning to implement this system.   Figure 3. System architecture Considering that pictures are a very important part of mind maps, we will use our server architecture to create a big database of pictures that are suitable for each word. We will make initial database with pictures for most common words, so the system will automatically place the pictures in the generated mind maps. For words without a picture in our database, users will be able to upload their own pictures. After a period of time, we will again have multiple suitable pictures for each of the words; therefore the users will be able to choose pictures they like for each word in their mind maps. They will always have an option of changing pictures of the given keywords because every person has different associations and it is very likely that not all automatically selected pictures will give appropriate associations for every user. More importantly, every user will probably always change at least a few pictures to adapt the generated mind map associations to his/her liking. Earlier in the text we’ve mentioned it was good for users to develop their own styles of mind mapping. Therefore we will provide editing features which will make it possible for the users to edit their mind maps. They will be able to 489 rearrange nodes, change colors, pictures and words. They will be able to fully customize their mind maps. The most important part of this software will be the algorithms that actually generate mind maps. Those algorithms should, among other things, analyze given text through relations between words in sentences, relations between sentences and between paragraphs, parsing of words that are irrelevant and based on those results, etc. After this analysis we can automatically generate mind map for a given text. If we look at this problem, we can’t just look headers of documents or some meta-data. This kind of algorithmic analysis would be a good starting point but for entirely plain texts it would not work. The algorithms should give good results for any given text, and we can’t predict in which form the text will be. The details about these algorithms will be presented in upcoming papers since this is the paper that describes the basic model of this system and algorithms for text-mining. When a mind map is generated, the user will be able to browse it, he will be able to search any term that was in the original text, and the search results will automatically mark nodes that are related with the search term. Also, when a user clicks on a particular node, he will see only the text relevant to that particular node. These are the main features that we consider important for a mind map generator to have. If we want to generate a mind map from a text the first thing we need is an algorithm that will parse this text. In the following section we will give a few examples of this parser at work. 3. Text-mining algorithm For every text that we want to generate a mind map from we need an algorithm that will parse the text and extract useful structured data. We need a text source as an input (document, web page) and this algorithm will give us extracted text for mind map generation as an output. The extracted text will be an input for the algorithm that will actually generate a mind map. If we have a pdf, doc, rtf or a document of another similar extension, there are no problems in text extraction since all we need to do is just take the entire content of the document. But, if we have a web page as a text source then we have a problem, since, obviously the needed text has to be extracted from the web code and here we need somewhat smarter algorithm that will do this extraction. If a web page is coded according to W3C standards the only thing that has to be done is to write a small algorithm with just a few regular expressions since it is not so difficult to find patterns in the code. There are also pages that do not conform to these laid out standards, and in order to resolve this situation we need a more complex special algorithm which will try the best it can to extract the text. The reason why it’s difficult to extract this text from a web page that does not conform to W3C standard is that these pages are poorly structured; the tags are badly encapsulated, unclosed, etc. Let’s first take a look at the pseudo code for this algorithm that we have developed and after that we will give some examples of inputs and outputs of the mentioned algorithm at runtime. Pseudo code: Input: Text from the following data sources (doc, docx, pdf, txt, rtf, web-page) Output: extracted text IF (data source = doc || docx || pdf || txt || rtf) Extract text data from the source document through standard algorithms for document manipulation ELSE Determine if web page conforms to W3C standards IF (conforms) Execute regular expressions to extract data from data source according to standard web-page structure laid out by the W3C ELSE Determine position of the text in the code through global code structure Refine text positioning through selective tag encapsulation Extract text from the code Now that we know how this algorithm works let’s see few examples of its execution. Extraction from documents will not be covered since this task is trivial but we will, of course, cover text extraction from web pages. Let’s see a few examples of text extraction from web pages that do not conform to W3C standards.  Data source:  http://edition.cnn.com/2011/OPINION/02/10/opinion.roundup.egypt/index.html?hpt=C2 loaded: 11. 02. 2011. W3C markup validation: 67 errors and 22 warnings. Results: Everything relevant was extracted from the web page, therefore, this web data source was 490 extracted satisfactory. Nevertheless, algorithm did make one mistake because it extracted a sentence that is not a part of the main text. Overall, these are good results since this mistake is a minor problem and probably won’t influence the mind map generator that will be developed. Data source: http://en.wikipedia.org/wiki/Mind_map loaded: 11. 02. 2011. W3C markup validation: 2 errors. 4. Conclusion and further research Mind maps are very useful in different fields, like learning, memorizing, structuring data and speeding up the search process; we could process much more information in less time etc. The process of creating a mind map is slow, and all the tools today are just editors that help us create mind maps. So if we generate mind maps from plain text, that reduces much of the time required to make mind maps and then we could focus on using them. We plan to develop a system that is based on this model, with all the features that we described. Further research is needed to implement all the features of this model. The developed text-mining algorithm will be a part of this system and outputs of this algorithm will be passed to a mind-map generator algorithm that is still in development. Development of such a system would contribute to the popularization of mind maps and we believe it would greatly increase the use of mind maps in many areas. Also, this compact way of presenting data with mind maps and then creating information and new knowledge from them is very useful in knowledge management where we could even implement some kind of reasoning over these maps and information that we created.  '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a42aa52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb46b56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5fead4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
